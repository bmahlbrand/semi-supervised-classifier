{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IaYl07Os1hiL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import STL10\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWzju5pa1hiP"
   },
   "outputs": [],
   "source": [
    "# Displaying routine\n",
    "def display_images(in_, out, n=1, label=None, count=False):\n",
    "    for N in range(n):\n",
    "        if in_ is not None:\n",
    "            in_pic = in_.data.cpu().view(-1, 96, 96)\n",
    "            plt.figure(figsize=(18, 4))\n",
    "            plt.suptitle(label + ' â€“ real test data / reconstructions', color='w', fontsize=16)\n",
    "            for i in range(4):\n",
    "                plt.subplot(1,4,i+1)\n",
    "                plt.imshow(in_pic[i+4*N])\n",
    "                plt.axis('off')\n",
    "        out_pic = out.data.cpu().view(-1, 96, 96)\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        for i in range(4):\n",
    "            plt.subplot(1,4,i+1)\n",
    "            plt.imshow(out_pic[i+4*N])\n",
    "            plt.axis('off')\n",
    "            if count: plt.title(str(4 * N + i), color='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hIhNacBE1hiR"
   },
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_XKppb-Y1hiU",
    "outputId": "143c4471-038f-408f-b470-fcec48800583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data\\stl10_binary.tar.gz\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Compressed file ended before the end-of-stream marker was reached",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-99b441d0bfb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m train_loader = torch.utils.data.DataLoader(\n\u001b[0;32m      7\u001b[0m     STL10('./data', download=True,\n\u001b[1;32m----> 8\u001b[1;33m                    transform=transforms.Compose([transforms.Resize((96,96)),transforms.ToTensor()])),\n\u001b[0m\u001b[0;32m      9\u001b[0m     batch_size=batch_size, shuffle=True, **kwargs)\n\u001b[0;32m     10\u001b[0m test_loader = torch.utils.data.DataLoader(STL10('./data', transform=transforms.Compose([transforms.Resize((96,96)),transforms.ToTensor()])),\n",
      "\u001b[1;32mc:\\users\\shift_000\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchvision\\datasets\\stl10.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, split, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shift_000\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mtar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r:gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mtar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0mtar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shift_000\\appdata\\local\\programs\\python\\python37\\lib\\tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[1;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[0;32m   2000\u001b[0m             \u001b[1;31m# Do not set_attrs directories, as we will do that further down\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m             self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[1;32m-> 2002\u001b[1;33m                          numeric_owner=numeric_owner)\n\u001b[0m\u001b[0;32m   2003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m         \u001b[1;31m# Reverse sort directories.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shift_000\\appdata\\local\\programs\\python\\python37\\lib\\tarfile.py\u001b[0m in \u001b[0;36mextract\u001b[1;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2042\u001b[0m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[0;32m   2043\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                                  numeric_owner=numeric_owner)\n\u001b[0m\u001b[0;32m   2045\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrorlevel\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shift_000\\appdata\\local\\programs\\python\\python37\\lib\\tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[1;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2115\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2116\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shift_000\\appdata\\local\\programs\\python\\python37\\lib\\tarfile.py\u001b[0m in \u001b[0;36mmakefile\u001b[1;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[0;32m   2161\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReadError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmakeunknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shift_000\\appdata\\local\\programs\\python\\python37\\lib\\tarfile.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[1;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremainder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unexpected end of data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shift_000\\appdata\\local\\programs\\python\\python37\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shift_000\\appdata\\local\\programs\\python\\python37\\lib\\_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shift_000\\appdata\\local\\programs\\python\\python37\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    480\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[0;32m    483\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
     ]
    }
   ],
   "source": [
    "# Define data loading step\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    STL10('./data', download=True,\n",
    "                   transform=transforms.Compose([transforms.Resize((96,96)),transforms.ToTensor()])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(STL10('./data', transform=transforms.Compose([transforms.Resize((96,96)),transforms.ToTensor()])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nII_-Sj11hiX"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNCU4nLjHrAw"
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class DeConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DeConvBlock, self).__init__()\n",
    "\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.deconv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ThhDCouHlEV"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.add_module('conv1', ConvBlock(64, 64))\n",
    "        self.add_module('maxpool1', nn.MaxPool2d(kernel_size=4, return_indices=True))\n",
    "        # (64)3c-3p-\n",
    "        self.add_module('conv2', ConvBlock(64, 128))\n",
    "        self.add_module('maxpool2', nn.MaxPool2d(kernel_size=3, return_indices=True))\n",
    "        # (128)3c-\n",
    "        self.add_module('conv3', ConvBlock(128, 128))\n",
    "        # (128)3c-2p-\n",
    "        self.add_module('conv4', ConvBlock(128, 256))\n",
    "        self.add_module('maxpool3', nn.MaxPool2d(kernel_size=2, return_indices=True))\n",
    "        # (256)3c-\n",
    "        self.add_module('conv5', ConvBlock(256, 256))\n",
    "        # (256)3c-\n",
    "        self.add_module('conv6', ConvBlock(256, 512))\n",
    "        # (256)3c-\n",
    "        self.add_module('conv7', ConvBlock(512, 512))\n",
    "        # (512)3c-\n",
    "        self.add_module('conv8', ConvBlock(512, 512))\n",
    "        # (512)3c-\n",
    "        # 'conv9', ConvBlock(512, 10))\n",
    "        self.add_module('maxpool4', nn.MaxPool2d(kernel_size=2, return_indices=True))\n",
    "        # (512)3c-2p-10fc \n",
    "        self.add_module('fc1', nn.Linear(2048, 10))\n",
    "        \n",
    "        # )\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._modules['conv1'](x)\n",
    "        x, indices1 = self._modules['maxpool1'](x)\n",
    "        x = self._modules['conv2'](x)\n",
    "        x, indices2 = self._modules['maxpool2'](x)\n",
    "        x = self._modules['conv3'](x)\n",
    "        x = self._modules['conv4'](x)\n",
    "        x, indices3 = self._modules['maxpool3'](x)\n",
    "        x = self._modules['conv5'](x)\n",
    "        x = self._modules['conv6'](x)\n",
    "        x = self._modules['conv7'](x)\n",
    "        x = self._modules['conv8'](x)\n",
    "        # x = self['conv9'](x)\n",
    "        x, indices4 = self._modules['maxpool4'](x)\n",
    "#         print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self._modules['fc1'](x)\n",
    "        return x, indices1, indices2, indices3, indices4\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # self.add_module(# (512)3c-2p-10fc \n",
    "            # 'fc1', nn.Linear(num_classes, 10))\n",
    "            # (512)3c-\n",
    "        self.add_module('fc1', nn.Linear(10, 2048))\n",
    "        self.add_module('unpool1', nn.MaxUnpool2d(kernel_size=2))\n",
    "        self.add_module('deconv1', DeConvBlock(512, 512))\n",
    "        # (512)3c-\n",
    "        self.add_module('deconv2', DeConvBlock(512, 512))\n",
    "        # (256)3c-\n",
    "        self.add_module('deconv3', DeConvBlock(512, 512))\n",
    "        # (256)3c-\n",
    "        self.add_module('deconv4', DeConvBlock(512, 256))\n",
    "        # (256)3c-\n",
    "        self.add_module('deconv5', DeConvBlock(256, 256))\n",
    "        # (128)3c-2p-\n",
    "        self.add_module('unpool2', nn.MaxUnpool2d(kernel_size=2))\n",
    "        self.add_module('deconv6', DeConvBlock(256, 128))\n",
    "        \n",
    "        # (128)3c-\n",
    "        self.add_module('deconv7', DeConvBlock(128, 128))\n",
    "        # (64)3c-3p-\n",
    "        self.add_module('deconv8', DeConvBlock(128, 64))\n",
    "        self.add_module('unpool3', nn.MaxUnpool2d(kernel_size=3))\n",
    "        # (64)3c-4p-\n",
    "        self.add_module('deconv9', DeConvBlock(64, 64))\n",
    "        self.add_module('unpool4', nn.MaxUnpool2d(kernel_size=4))\n",
    "\n",
    "    def forward(self, x, indices1, indices2, indices3, indices4):\n",
    "        x = self._modules['fc1'](x)\n",
    "#         print(x.shape)\n",
    "        x = x.reshape(256, 512, 2,2)\n",
    "        x = self._modules['unpool1'](x, indices4)\n",
    "        x = self._modules['deconv1'](x)\n",
    "        x = self._modules['deconv2'](x)\n",
    "        x = self._modules['deconv3'](x)\n",
    "        x = self._modules['deconv4'](x)\n",
    "        x = self._modules['deconv5'](x)\n",
    "        x = self._modules['unpool2'](x, indices3)\n",
    "        x = self._modules['deconv6'](x)\n",
    "        \n",
    "        x = self._modules['deconv7'](x)\n",
    "        x = self._modules['unpool3'](x, indices2)\n",
    "        x = self._modules['deconv8'](x)\n",
    "        x = self._modules['unpool4'](x, indices1)\n",
    "        x = self._modules['deconv9'](x)\n",
    "#         print('decoder.forward output:', x.shape)\n",
    "        return x\n",
    "\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "\n",
    "        # self.encoder = nn.Sequential(\n",
    "        self.conv0 = nn.Conv2d(3, 64, kernel_size=1)\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "        \n",
    "        self.convFinal = nn.Conv2d(64, 3, kernel_size=1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.data.new(std.size()).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        \n",
    "        mu_logvar, indices1, indices2, indices3, indices4 = self.encoder(x)\n",
    "        \n",
    "#         print(mu_logvar.shape)\n",
    "        \n",
    "        mu_logvar = mu_logvar.view(-1, 2, 10)\n",
    "#         # mu_logvar = self.encoder(x.view(-1, 1000)).view(-1, 2, d)\n",
    "    \n",
    "#         print(mu_logvar.shape)\n",
    "    \n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = self.decoder(mu_logvar, indices1, indices2, indices3, indices4)\n",
    "\n",
    "#         z = self.avgpool(z)\n",
    "#         z = z.view(z.size(0), -1)\n",
    "#         z = self.classifier(z)\n",
    "\n",
    "#         return z, mu, logvar\n",
    "\n",
    "        z = self.convFinal(z)\n",
    "        return z, mu, logvar\n",
    "    \n",
    "    @staticmethod\n",
    "    def loss_function(x_hat, x, mu, logvar):\n",
    "        BCE = nn.functional.binary_cross_entropy(\n",
    "            x_hat, x.view(-1, dataset_resolution), reduction='sum'\n",
    "        )\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        \n",
    "        return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0gO72DSH1hia"
   },
   "outputs": [],
   "source": [
    "d = 20\n",
    "num_classes = 10\n",
    "# 28 * 28 for MNIST\n",
    "dataset_resolution = 96 * 96\n",
    "        \n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(dataset_resolution, d ** 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d ** 2, d ** 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d ** 2, d * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(d, d ** 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d ** 2, d ** 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d ** 2, dataset_resolution),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def reparameterise(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = std.data.new(std.size()).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu_logvar = self.encoder(x.view(-1, dataset_resolution)).view(-1, 2, d)\n",
    "        mu = mu_logvar[:, 0, :]\n",
    "        logvar = mu_logvar[:, 1, :]\n",
    "        z = self.reparameterise(mu, logvar)\n",
    "        z = self.decoder(z)\n",
    "#         z = self.avgpool(z)\n",
    "#         z = z.view(z.size(0), -1)\n",
    "        return z, mu, logvar\n",
    "#         return self.classifier(z), mu, logvar\n",
    "\n",
    "\n",
    "\n",
    "# model = VAE().to(device)\n",
    "\n",
    "model = VariationalAutoEncoder(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSjV0QQSN6zq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMY7cZWU1hic"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zi4h34_31hif"
   },
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "\n",
    "def loss_function(x_hat, x, mu, logvar):\n",
    "#     BCE = nn.functional.binary_cross_entropy(\n",
    "#         x_hat, x.view(-1, dataset_resolution), reduction='sum'\n",
    "#     )\n",
    "    BCE = nn.functional.mse_loss(\n",
    "        x_hat, x, reduction='sum'\n",
    "    )\n",
    "    \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return BCE + KLD\n",
    "\n",
    "# def loss_function(x_hat, x):\n",
    "#     return torch.sum(x_hat.pow(2))\n",
    "#     return nn.functional.mse_loss(x)\n",
    "#      return nn.functional.binary_cross_entropy(\n",
    "#         x_hat, x.view(-1, dataset_resolution), reduction='sum'\n",
    "#      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jj9q1cC11hii",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training and testing the VAE\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, _ in train_loader:\n",
    "        x = x.to(device)\n",
    "        # ===================forward=====================\n",
    "        x_hat, mu, logvar = model(x)\n",
    "#         print('x_hat', x_hat.shape)\n",
    "#         print('x', x.shape)\n",
    "#         print('mu', mu.shape)\n",
    "#         print('logvar', logvar.shape)\n",
    "#         x_hat = model(x)\n",
    "        loss = loss_function(x_hat, x, mu, logvar)\n",
    "#         loss = loss_function(x_hat, x)\n",
    "#         print(loss.item())\n",
    "        train_loss += loss.item()\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print(f'====> Epoch: {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}')\n",
    "    \n",
    "    # Testing\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        for x, _ in test_loader:\n",
    "            x = x.to(device)\n",
    "            # ===================forward=====================\n",
    "            x_hat, mu, logvar = model(x)\n",
    "            test_loss += loss_function(x_hat, x, mu, logvar).item()\n",
    "    # ===================log========================\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'====> Test set loss: {test_loss:.4f}')\n",
    "    display_images(x, x_hat, 1, f'Epoch {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dY3hPGUK1hil"
   },
   "outputs": [],
   "source": [
    "# Generating a few samples\n",
    "\n",
    "N = 16\n",
    "sample = torch.randn((N, d)).to(device)\n",
    "sample = model.decoder(sample)\n",
    "display_images(None, sample, N // 4, count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAUm-OQM1hio"
   },
   "outputs": [],
   "source": [
    "# Display last test batch\n",
    "\n",
    "display_images(None, x, 4, count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0p1mFAJ1hir"
   },
   "outputs": [],
   "source": [
    "# Choose starting and ending point for the interpolation -> shows original and reconstructed\n",
    "\n",
    "A, B = 3, 8\n",
    "sample = model.decoder(torch.stack((mu[A].data, mu[B].data), 0))\n",
    "display_images(None, torch.stack(((\n",
    "    x[A].data.view(-1),\n",
    "    x[B].data.view(-1),\n",
    "    sample.data[0],\n",
    "    sample.data[1]\n",
    ")), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXTDVgdv1hiu"
   },
   "outputs": [],
   "source": [
    "# Perform an interpolation between input A and B, in N steps\n",
    "\n",
    "N = 16\n",
    "code = torch.Tensor(N, 20).to(device)\n",
    "for i in range(N):\n",
    "    code[i] = i / (N - 1) * mu[B].data + (1 - i / (N - 1) ) * mu[A].data\n",
    "sample = model.decoder(code)\n",
    "display_images(None, sample, N // 4, count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "11-VAE.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
